#  # Config for training ALAE on FFHQ at resolution 1024x1024

# NAME: ecog
# DATASET:
#   PART_COUNT: 16
#   SIZE: 60000
#   FFHQ_SOURCE: /data/datasets/ffhq-dataset/tfrecords/ffhq/ffhq-r%02d.tfrecords
#   PATH: /data/datasets/ffhq-dataset_new/tfrecords/ffhq/splitted/ffhq-r%02d.tfrecords.%03d

#   FLIP_IMAGES: False

#   PART_COUNT_TEST: 4
#   PATH_TEST: /data/datasets/ffhq-dataset_new/tfrecords/ffhq-test/splitted/ffhq-r%02d.tfrecords.%03d

#   SAMPLES_PATH: ''
#   STYLE_MIX_PATH: style_mixing/test_images/set_ecog
#   SPEC_CHANS: 64
#   TEMPORAL_SAMPLES: 128
#   BCTS: True
#   MAX_RESOLUTION_LEVEL: 7
#   # SELECTREGION: ["AUDITORY","BROCA","MOTO","SENSORY","PARIETAL"]
#   # SELECTREGION: ["BROCA","MOTO","SENSORY"]
#   SELECTREGION: ["AUDITORY","BROCA","MOTO","SENSORY"]
#   BLOCKREGION: []
#   SUBJECT: ['NY742']
#   PROD: True
#   PRE_ARTICULATE: False 
#   TRIM: True
# MODEL:
#   #####TAKE OFF CHECKLIST!!!########
#   N_FORMANTS: 6
#   N_FORMANTS_NOISE: 1
#   N_FORMANTS_ECOG: 6
#   WAVE_BASED : True
#   DO_MEL_GUIDE : False 
#   BGNOISE_FROMDATA: True
#   N_FFT : 256 #512
#   NOISE_DB : -50 #-50
#   MAX_DB : 22.5 #probablity 28 is better
#   NOISE_DB_AMP : -25
#   MAX_DB_AMP : 14
#   POWER_SYNTH: True
#   NORMED_MASK: False
#   DUMMY_FORMANT: False
#   LEARNED_MASK: False
#   N_FILTER_SAMPLES: 20
#   CAUSAL: False
#   ANTICAUSAL: False
  


#   LESS_TEMPORAL_FEATURE: True
#   LATENT_SPACE_SIZE: 128
#   LAYER_COUNT: 6
#   MAX_CHANNEL_COUNT: 512
#   START_CHANNEL_COUNT: 16
#   DLATENT_AVG_BETA: 0.995
#   MAPPING_LAYERS: 8
#   TRUNCATIOM_CUTOFF: 5
#   CHANNELS: 1
#   UNIQ_WORDS: 50
#   MAPPING_FROM_ECOG: "ECoGMappingBottleneck"
#   # MAPPING_FROM_ECOG: "Enc3DAttAug"
#   # MAPPING_FROM_ECOG: "Transformer_EncDec"
#   # MAPPING_FROM_ECOG: "ECoGMappingPerformer2Dconv_downsample1_posemb"
#   # MAPPING_FROM_ECOG: "ECoGMappingPerformer3Dconv_downsample1_posemb_flatten"
#   # MAPPING_FROM_ECOG: "ECoGMappingBottleneck3DAttAug"
#   # MAPPING_FROM_ECOG: "ECoGMappingTransformer"
#   ECOG: False #will be overloaded if FINETUNE
#   SUPLOSS_ON_ECOGF: False # will be overloaded to FIX_GEN if FINETUNE,spec supervise loss only apply to ecog encoder
#   W_SUP: False
#   GAN: True
#   GENERATOR: "GeneratorFormant"
#   ENCODER: "EncoderFormant"
#   ECOG_COMPUTE_DB_LOUDNESS: True
#   AVERAGE_W: True
#   TEMPORAL_W: True
#   GLOBAL_W: True
#   TEMPORAL_GLOBAL_CAT: True
#   RESIDUAL: True
#   W_CLASSIFIER: False
#   CYCLE: False
#   ATTENTIONAL_STYLE: True
#   #T            4      8      16    32    64    128 
#   ATTENTION: [False, False, False, False, False, False]
#   HEADS: 1
#   APPLY_PPL: False 
#   APPLY_PPL_D: False
#   PPL_WEIGHT: 100
#   PPL_GLOBAL_WEIGHT: 0
#   PPLD_WEIGHT: 1
#   PPLD_GLOBAL_WEIGHT: 0
#   COMMON_Z: True

#   TRANSFORMER:
#     HIDDEN_DIM : 256
#     DIM_FEEDFORWARD : 256
#     ENCODER_ONLY : True
#     ATTENTIONAL_MASK : False
#     N_HEADS : 8
#     NON_LOCAL: False

#   # ATTENTION: []
# # OUTPUT_DIR: training_artifacts/debug_fitalphaonly_crossentropy
# # OUTPUT_DIR: training_artifacts/debug__
# # OUTPUT_DIR: training_artifacts/debug_han5amppowerloss_reweightflooding_dbmelloss_trim5_casual
# # OUTPUT_DIR: training_artifacts/loudnesscomp_han11_ampamploss
# # OUTPUT_DIR: training_artifacts/loudnesscomp_han15_amppowerloss
# # OUTPUT_DIR: training_artifacts/742_encoder4visA2Abroud2D
# # OUTPUT_DIR: training_artifacts/798_loudnesscomp_han5_amppowerloss_limitmelloss_nodenoiseloss_NewFRange_manualgengauss2_normedmask_amprereweight_silientmore_loudnessfromamp_powernorm_noiseampbias_noiseformantmorefreedom_lessbandwidth
# # OUTPUT_DIR: training_artifacts/749_han5amppowerloss_ecogfinetune
# # OUTPUT_DIR: training_artifacts/ecog_fintune_742_han5amppowerloss_prod_amp
# # OUTPUT_DIR: training_artifacts/717_han5amppowerloss_ecogfinetune_selectall
# # OUTPUT_DIR: training_artifacts/742_han5amppowerloss_dummy_percept
# # OUTPUT_DIR: training_artifacts/742_han5amppowerloss_alphasupbandwfricative
# # OUTPUT_DIR: training_artifacts/749_han5amppowerloss_ecogfintune
# # OUTPUT_DIR: training_artifacts/742_han5amppowerloss_ecogfintune_alphasup3_newlossnoiseamp_causal
# # OUTPUT_DIR: training_artifacts/749_han5amppowerloss_ecogfinetune_woaud
# # OUTPUT_DIR: training_artifacts/717_han5amppowerloss_ecogfinetune_prearti
# # OUTPUT_DIR: training_artifacts/717_han5amppowerloss_ecogfinetune_withparietal
# # OUTPUT_DIR: training_artifacts/742_han5amppowerloss_ecogfinetune_fixedpe_3D_attaugwider_mniemb_realMAXPool_3attauglayers
# # OUTPUT_DIR: training_artifacts/742_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim_causal
# # OUTPUT_DIR: training_artifacts/749_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim_causal_audonly
# # OUTPUT_DIR: training_artifacts/798_loudnesscomp_han5_amppowerloss_limitmelloss_nodenoiseloss_NewFRange_512nfft_gengauss_normedmask_alphapenalty10_hamnonicbias
# # OUTPUT_DIR: training_artifacts/798_loudnesscomp_han5_ecogfinetune_alphasup3_dummyf_learnedmask_monocubic
# # OUTPUT_DIR: training_artifacts/798_loudnesscomp_han5_alphasup3_dummyf_learnedmask_realyrun1run2_monocubic
# # OUTPUT_DIR: training_artifacts/798_loudnesscomp_han5_alphasup3_dummyf_learnedmask_nfiltersample20
# # OUTPUT_DIR: training_artifacts/742_han5amppowerloss_ecogfinetune_alphasup3_groupnorm_ModifiedOutputLayer
# # OUTPUT_DIR: training_artifacts/798_loudnesscomp_han5_ecogfinetune_alphasup3_dummyf_learnedmask_testonWCR_WCR
# # OUTPUT_DIR: training_artifacts/debug_f1f2linearmel
# # OUTPUT_DIR: training_artifacts/ecog_finetune_3ecogformants_han5_specsup_guidance_hamonicformantsemph
# # OUTPUT_DIR: training_artifacts/ecog_finetune_3ecogformants_han5_specsup_guidance_hamonicnoiseformantsemphmore
# # OUTPUT_DIR: training_artifacts/formantsythv2_wavebased_NY742_constraintonFB_Bconstrainrefined_absfreq_4formants_1noiseformants_bgnoise_noisemapping_freqconv_duomask
# # OUTPUT_DIR: training_artifacts/ecog_residual_latent128_temporal_lesstemporalfeature_noprogressive_HBw_ppl_ppld_localreg_ecogf_w_spec_sup
# # OUTPUT_DIR: training_artifacts/ecog_residual_latent128_temporal_lesstemporalfeature_ppl_ppld
# # OUTPUT_DIR: training_artifacts/ecog_residual_cycle_attention3264wStyleIN_specchan64_more_attentfeatures_heads4
# OUTPUT_DIR: training_artifacts/742_han5amppowerloss_alphasup3_percept

# IGNORE_LOADING: True
# # LOAD_DIR: './training_artifacts/ecog_finetune_3ecogformants_han5_specsup_guidance_hamonicformantsemph/model_epoch23.pth'
# # LOAD_DIR: './training_artifacts/debug_f1f2linearmel/model_epoch27.pth'
# # LOAD_DIR: './training_artifacts/debug_fitf1f2freqonly/model_epoch28.pth'
# # LOAD_DIR: './training_artifacts/717_han5amppowerloss_ecogfinetune_prearti/model_epoch26.pth'
# # LOAD_DIR: './training_artifacts/798_loudnesscomp_han5_alphasup3_dummyf_learnedmask_run1run2/model_epoch46.pth'
# # LOAD_DIR: './training_artifacts/798_loudnesscomp_han5_alphasup3_dummyf_learnedmask_nfiltersample20/model_epoch59.pth'
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss_alphasup/model_epoch59.pth'
# # LAOD_DIR: './training_artifacts/742_han5amppowerloss_alphasup/model_epoch31.pth'
# # LOAD_DIR: './training_artifacts/717_han5amppowerloss_alphasup/model_epoch24.pth'
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss/model_epoch33.pth'
# # LOAD_DIR: './training_artifacts/717_han5amppowerloss/model_epoch56.pth'
# # LAOD_DIR: './training_artifacts/742_han5amppowerloss_ecogfinetune_tranformerencdec/model_epoch10.pth'
# # LAOD_DIR: './training_artifacts/loudnesscomp_han5_amppowerloss/model_epoch57.pth'
# # LOAD_DIR: './training_artifacts/ecog_fintune_749_han5amppowerloss_dummy_percept/model_epoch31.pth'
# # LOAD_DIR: './training_artifacts/ecog_fintune_742_han5amppowerloss_prod_amp/model_epoch32.pth'
# # LOAD_DIR: './training_artifacts/742_han5amppowerloss_dummy_percept/model_epoch59.pth'
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_alltask2_percept/model_epoch39.pth'
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss/model_epoch33.pth'
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_selectall/model_epoch36.pth'
# # LOAD_DIR: './training_artifacts/717_han5amppowerloss_ecogfinetune_selectall/model_epoch37.pth'
# # LOAD_DIR: './training_artifacts/debug_han5amppowerloss_dbmelloss_reweightflooding_selectall/model_epoch36.pth'
# # LOAD_DIR: './training_artifacts/debug_han5amppowerloss_dbmelloss_reweightflooding/model_epoch57.pth'
# LOAD_DIR: './training_artifacts/debug_han5amppowerloss_dbmelloss_reweightflooding/model_epoch38.pth' 
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim/model_epoch30.pth'
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim/model_epoch30.pth'
# # LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim/model_epoch30.pth'
# # LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim_causal/model_epoch30.pth'
# # LOAD_DIR: './training_artifacts/717_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim_anticausal_woaud/model_epoch30.pth'
# # LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim_anticausal/model_epoch30.pth'
# # LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfintune_alphasup3_newlossnoiseamp_causal/model_epoch49.pth'
# # LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfintune_alphasup3_newlossnoiseamp_anticausal/model_epoch45.pth'
# # LOAD_DIR: './training_artifacts/717_han5amppowerloss_ecogfinetune/model_epoch30.pth' 
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune/model_epoch27.pth'
# # LOAD_DIR: './training_artifacts/717_han5amppowerloss_ecogfinetune_withparietal/model_epoch36.pth'
# # LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfinetune_withparietal/model_epoch35.pth'
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_withparietal/model_epoch33.pth'
# # LOAD_DIR: './training_artifacts/717_han5amppowerloss_ecogfinetune_woaud/model_epoch31.pth'
# # LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfinetune_woaud/model_epoch29.pth'
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_woaud/model_epoch30.pth'
# # LOAD_DIR: './training_artifacts/798_loudnesscomp_han5_amppowerloss_limitmelloss_nodenoiseloss_NewFRange_512nfft_manualgengauss_normedmask_amprereweight_silientmore_dummyformantharmononly_loudnessfromamp2_powernorm_noamplitudesmooth/model_epoch57.pth'
# # LOAD_DIR: './training_artifacts/742_encoder4visA2Abroud2D/model_epoch10.pth'
# # LOAD_DIR: './training_artifacts/717_han5amppowerloss_ecogfinetune_woaud/model_epoch31.pth'
# # LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfinetune_woaud/model_epoch29.pth'
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_woaud/model_epoch30.pth'
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_prearti/model_epoch59.pth'
# # LOAD_DIR: './training_artifacts/loudnesscomp_han5_amppowerloss/model_epoch57.pth'
# # LOAD_DIR: './training_artifacts/loudnesscomp_han5_ampamploss/model_epoch59.pth'
# # LOAD_DIR: './training_artifacts/loudnesscomp_han5_ampamploss_denoiswaveloudness/model_epoch6.pth'
# # LOAD_DIR: './training_artifacts/test_9/model_epoch30.pth'

# FINETUNE:
#   FINETUNE: False 
#   FIX_GEN: True
#   ENCODER_GUIDE: True
#   SPECSUP: True
#   APPLY_FLOODING: True

# VISUAL:
#   VISUAL: False
#   KEY: 'freq_formants_hamon'
#   INDEX: [0]
#   A2A: False
# #####################################

# TRAIN:
#   PROGRESSIVE: False
#   W_WEIGHT: 1
#   CYCLE_WEIGHT: 1
#   BASE_LEARNING_RATE: 0.002
#   EPOCHS_PER_LOD: 16
#   LEARNING_DECAY_RATE: 0.1
#   LEARNING_DECAY_STEPS: [96]
#   TRAIN_EPOCHS: 60
#   #                    4    8   16    32    64    128    256
#   LOD_2_BATCH_8GPU: [512, 256, 128,   64,   32,    32] # If GPU memory ~16GB reduce last number from 32 to 24
#   LOD_2_BATCH_4GPU: [64, 64, 64,   64,   32,    16]
#   LOD_2_BATCH_2GPU: [64, 64, 64,   64,   32,    16]
#   # LOD_2_BATCH_1GPU: [512, 256, 128,   64,   32,    16]
#   # LOD_2_BATCH_1GPU: [512, 256, 128,   64,   32,    32]
#   # LOD_2_BATCH_1GPU: [512, 256, 128,   64,   32,    16]
#   # LOD_2_BATCH_1GPU: [128, 128, 128,   128,   64,    32]
#   # LOD_2_BATCH_1GPU: [512, 256, 256,   128,   64,    16]
#   LOD_2_BATCH_1GPU: [64, 64, 64,   64,   32,    16]
#   BATCH_SIZE : 32
#   # BATCH_SIZE : 2
#   LEARNING_RATES: [0.0015,  0.0015,   0.0015,    0.002,     0.003,    0.003]
#   # LEARNING_RATES: [0.0015,  0.0015,   0.0005,    0.0003,     0.0003,    0.0002]











## 798
NAME: ecog
DATASET:
  PART_COUNT: 16
  SIZE: 60000
  FFHQ_SOURCE: /data/datasets/ffhq-dataset/tfrecords/ffhq/ffhq-r%02d.tfrecords
  PATH: /data/datasets/ffhq-dataset_new/tfrecords/ffhq/splitted/ffhq-r%02d.tfrecords.%03d

  FLIP_IMAGES: False

  PART_COUNT_TEST: 4
  PATH_TEST: /data/datasets/ffhq-dataset_new/tfrecords/ffhq-test/splitted/ffhq-r%02d.tfrecords.%03d

  SAMPLES_PATH: ''
  STYLE_MIX_PATH: style_mixing/test_images/set_ecog
  SPEC_CHANS: 64
  TEMPORAL_SAMPLES: 128
  BCTS: True
  MAX_RESOLUTION_LEVEL: 7
  # SELECTREGION: ["AUDITORY","BROCA","MOTO","SENSORY","PARIETAL"]
  # SELECTREGION: ["BROCA","MOTO","SENSORY"]
  SELECTREGION: ["AUDITORY","BROCA","MOTO","SENSORY"]
  BLOCKREGION: []
  SUBJECT: ['NY798']
  PROD: True
  PRE_ARTICULATE: False 
  TRIM: True
MODEL:
  #####TAKE OFF CHECKLIST!!!########
  N_FORMANTS: 6
  N_FORMANTS_NOISE: 1
  N_FORMANTS_ECOG: 6
  WAVE_BASED : True
  DO_MEL_GUIDE : False 
  BGNOISE_FROMDATA: True
  N_FFT : 512 #512
  NOISE_DB : -50 #-50
  MAX_DB : 22.5 #probablity 28 is better
  NOISE_DB_AMP : -25
  MAX_DB_AMP : 14
  POWER_SYNTH: True
  NORMED_MASK: False
  DUMMY_FORMANT: True
  LEARNED_MASK: True
  N_FILTER_SAMPLES: 20
  CAUSAL: True
  ANTICAUSAL: True

  LESS_TEMPORAL_FEATURE: True
  LATENT_SPACE_SIZE: 128
  LAYER_COUNT: 6
  MAX_CHANNEL_COUNT: 512
  START_CHANNEL_COUNT: 16
  DLATENT_AVG_BETA: 0.995
  MAPPING_LAYERS: 8
  TRUNCATIOM_CUTOFF: 5
  CHANNELS: 1
  UNIQ_WORDS: 50
  MAPPING_FROM_ECOG: "ECoGMappingBottleneck"
  # MAPPING_FROM_ECOG: "Enc3DAttAug"
  # MAPPING_FROM_ECOG: "Transformer_EncDec"
  # MAPPING_FROM_ECOG: "ECoGMappingPerformer2Dconv_downsample1_posemb"
  # MAPPING_FROM_ECOG: "ECoGMappingPerformer3Dconv_downsample1_posemb_flatten"
  # MAPPING_FROM_ECOG: "ECoGMappingBottleneck3DAttAug"
  # MAPPING_FROM_ECOG: "ECoGMappingTransformer"
  ECOG: False #will be overloaded if FINETUNE
  SUPLOSS_ON_ECOGF: False # will be overloaded to FIX_GEN if FINETUNE,spec supervise loss only apply to ecog encoder
  W_SUP: False
  GAN: True
  GENERATOR: "GeneratorFormant"
  ENCODER: "EncoderFormant"
  ECOG_COMPUTE_DB_LOUDNESS: True
  AVERAGE_W: True
  TEMPORAL_W: True
  GLOBAL_W: True
  TEMPORAL_GLOBAL_CAT: True
  RESIDUAL: True
  W_CLASSIFIER: False
  CYCLE: False
  ATTENTIONAL_STYLE: True
  #T            4      8      16    32    64    128 
  ATTENTION: [False, False, False, False, False, False]
  HEADS: 1
  APPLY_PPL: False 
  APPLY_PPL_D: False
  PPL_WEIGHT: 100
  PPL_GLOBAL_WEIGHT: 0
  PPLD_WEIGHT: 1
  PPLD_GLOBAL_WEIGHT: 0
  COMMON_Z: True

  TRANSFORMER:
    HIDDEN_DIM : 256
    DIM_FEEDFORWARD : 256
    ENCODER_ONLY : True
    ATTENTIONAL_MASK : False
    N_HEADS : 8
    NON_LOCAL: False

  # ATTENTION: []
# OUTPUT_DIR: training_artifacts/debug_fitalphaonly_crossentropy
# OUTPUT_DIR: training_artifacts/debug__
# OUTPUT_DIR: training_artifacts/debug_han5amppowerloss_reweightflooding_dbmelloss_trim5_casual
# OUTPUT_DIR: training_artifacts/loudnesscomp_han11_ampamploss
# OUTPUT_DIR: training_artifacts/loudnesscomp_han15_amppowerloss
# OUTPUT_DIR: training_artifacts/742_encoder4visA2Abroud2D
# OUTPUT_DIR: training_artifacts/798_loudnesscomp_han5_amppowerloss_limitmelloss_nodenoiseloss_NewFRange_manualgengauss2_normedmask_amprereweight_silientmore_loudnessfromamp_powernorm_noiseampbias_noiseformantmorefreedom_lessbandwidth
# OUTPUT_DIR: training_artifacts/749_han5amppowerloss_ecogfinetune
# OUTPUT_DIR: training_artifacts/ecog_fintune_742_han5amppowerloss_prod_amp
# OUTPUT_DIR: training_artifacts/717_han5amppowerloss_ecogfinetune_selectall
# OUTPUT_DIR: training_artifacts/742_han5amppowerloss_dummy_percept
# OUTPUT_DIR: training_artifacts/742_han5amppowerloss_alphasupbandwfricative
# OUTPUT_DIR: training_artifacts/749_han5amppowerloss_ecogfintune
# OUTPUT_DIR: training_artifacts/742_han5amppowerloss_ecogfintune_alphasup3_newlossnoiseamp_causal
# OUTPUT_DIR: training_artifacts/749_han5amppowerloss_ecogfinetune_woaud
# OUTPUT_DIR: training_artifacts/717_han5amppowerloss_ecogfinetune_prearti
# OUTPUT_DIR: training_artifacts/717_han5amppowerloss_ecogfinetune_withparietal
# OUTPUT_DIR: training_artifacts/742_han5amppowerloss_ecogfinetune_fixedpe_3D_attaugwider_mniemb_realMAXPool_3attauglayers
# OUTPUT_DIR: training_artifacts/742_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim_causal
# OUTPUT_DIR: training_artifacts/749_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim_causal_audonly
# OUTPUT_DIR: training_artifacts/798_loudnesscomp_han5_amppowerloss_limitmelloss_nodenoiseloss_NewFRange_512nfft_gengauss_normedmask_alphapenalty10_hamnonicbias
# OUTPUT_DIR: training_artifacts/798_loudnesscomp_han5_ecogfinetune_alphasup3_dummyf_learnedmask_monocubic
# OUTPUT_DIR: training_artifacts/798_loudnesscomp_han5_alphasup3_dummyf_learnedmask_realyrun1run2_monocubic
OUTPUT_DIR: training_artifacts/798_loudnesscomp_han5_alphasup3_dummyf_learnedmask_nfiltersample20
# OUTPUT_DIR: training_artifacts/798_loudnesscomp_han5_ecogfinetune_alphasup3_dummyf_learnedmask_nfiltersample20_run1run2WCR_anticausal
# OUTPUT_DIR: training_artifacts/798_loudnesscomp_han5_ecogfinetune_alphasup3_dummyf_learnedmask_testonWCR_WCR
# OUTPUT_DIR: training_artifacts/debug_f1f2linearmel
# OUTPUT_DIR: training_artifacts/ecog_finetune_3ecogformants_han5_specsup_guidance_hamonicformantsemph
# OUTPUT_DIR: training_artifacts/ecog_finetune_3ecogformants_han5_specsup_guidance_hamonicnoiseformantsemphmore
# OUTPUT_DIR: training_artifacts/formantsythv2_wavebased_NY742_constraintonFB_Bconstrainrefined_absfreq_4formants_1noiseformants_bgnoise_noisemapping_freqconv_duomask
# OUTPUT_DIR: training_artifacts/ecog_residual_latent128_temporal_lesstemporalfeature_noprogressive_HBw_ppl_ppld_localreg_ecogf_w_spec_sup
# OUTPUT_DIR: training_artifacts/ecog_residual_latent128_temporal_lesstemporalfeature_ppl_ppld
# OUTPUT_DIR: training_artifacts/ecog_residual_cycle_attention3264wStyleIN_specchan64_more_attentfeatures_heads4

IGNORE_LOADING: False
# LOAD_DIR: './training_artifacts/ecog_finetune_3ecogformants_han5_specsup_guidance_hamonicformantsemph/model_epoch23.pth'
# LOAD_DIR: './training_artifacts/debug_f1f2linearmel/model_epoch27.pth'
# LOAD_DIR: './training_artifacts/debug_fitf1f2freqonly/model_epoch28.pth'
# LOAD_DIR: './training_artifacts/717_han5amppowerloss_ecogfinetune_prearti/model_epoch26.pth'
# LOAD_DIR: './training_artifacts/798_loudnesscomp_han5_alphasup3_dummyf_learnedmask_run1run2/model_epoch46.pth'
# LOAD_DIR: './training_artifacts/798_loudnesscomp_han5_ecogfinetune_alphasup3_dummyf_learnedmask_nfiltersample20_run1run2WCR_anticausal/model_epoch40.pth'
LOAD_DIR: './training_artifacts/798_loudnesscomp_han5_alphasup3_dummyf_learnedmask_nfiltersample20/model_epoch59.pth'
# LOAD_DIR: './training_artifacts/749_han5amppowerloss_alphasup/model_epoch59.pth'
# LAOD_DIR: './training_artifacts/742_han5amppowerloss_alphasup/model_epoch31.pth'
# LOAD_DIR: './training_artifacts/717_han5amppowerloss_alphasup/model_epoch24.pth'
# LOAD_DIR: './training_artifacts/749_han5amppowerloss/model_epoch33.pth'
# LOAD_DIR: './training_artifacts/717_han5amppowerloss/model_epoch56.pth'
# LAOD_DIR: './training_artifacts/742_han5amppowerloss_ecogfinetune_tranformerencdec/model_epoch10.pth'
# LAOD_DIR: './training_artifacts/loudnesscomp_han5_amppowerloss/model_epoch57.pth'
# LOAD_DIR: './training_artifacts/ecog_fintune_749_han5amppowerloss_dummy_percept/model_epoch31.pth'
# LOAD_DIR: './training_artifacts/ecog_fintune_742_han5amppowerloss_prod_amp/model_epoch32.pth'
# LOAD_DIR: './training_artifacts/742_han5amppowerloss_dummy_percept/model_epoch59.pth'
# LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_alltask2_percept/model_epoch39.pth'
# LOAD_DIR: './training_artifacts/749_han5amppowerloss/model_epoch33.pth'
# LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_selectall/model_epoch36.pth'
# LOAD_DIR: './training_artifacts/717_han5amppowerloss_ecogfinetune_selectall/model_epoch37.pth'
# LOAD_DIR: './training_artifacts/debug_han5amppowerloss_dbmelloss_reweightflooding_selectall/model_epoch36.pth'
# LOAD_DIR: './training_artifacts/debug_han5amppowerloss_dbmelloss_reweightflooding/model_epoch57.pth'
# LOAD_DIR: './training_artifacts/debug_han5amppowerloss_dbmelloss_reweightflooding/model_epoch38.pth'
# LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim/model_epoch30.pth'
# LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim/model_epoch30.pth'
# LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim/model_epoch30.pth'
# LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim_causal/model_epoch30.pth'
# LOAD_DIR: './training_artifacts/717_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim_anticausal_woaud/model_epoch30.pth'
# LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim_anticausal/model_epoch30.pth'
# LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfintune_alphasup3_newlossnoiseamp_causal/model_epoch49.pth'
# LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfintune_alphasup3_newlossnoiseamp_anticausal/model_epoch45.pth'
# LOAD_DIR: './training_artifacts/717_han5amppowerloss_ecogfinetune/model_epoch30.pth' 
# LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune/model_epoch27.pth'
# LOAD_DIR: './training_artifacts/717_han5amppowerloss_ecogfinetune_withparietal/model_epoch36.pth'
# LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfinetune_withparietal/model_epoch35.pth'
# LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_withparietal/model_epoch33.pth'
# LOAD_DIR: './training_artifacts/717_han5amppowerloss_ecogfinetune_woaud/model_epoch31.pth'
# LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfinetune_woaud/model_epoch29.pth'
# LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_woaud/model_epoch30.pth'
# LOAD_DIR: './training_artifacts/798_loudnesscomp_han5_amppowerloss_limitmelloss_nodenoiseloss_NewFRange_512nfft_manualgengauss_normedmask_amprereweight_silientmore_dummyformantharmononly_loudnessfromamp2_powernorm_noamplitudesmooth/model_epoch57.pth'
# LOAD_DIR: './training_artifacts/742_encoder4visA2Abroud2D/model_epoch10.pth'
# LOAD_DIR: './training_artifacts/717_han5amppowerloss_ecogfinetune_woaud/model_epoch31.pth'
# LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfinetune_woaud/model_epoch29.pth'
# LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_woaud/model_epoch30.pth'
# LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_prearti/model_epoch59.pth'
# LOAD_DIR: './training_artifacts/loudnesscomp_han5_amppowerloss/model_epoch57.pth'
# LOAD_DIR: './training_artifacts/loudnesscomp_han5_ampamploss/model_epoch59.pth'
# LOAD_DIR: './training_artifacts/loudnesscomp_han5_ampamploss_denoiswaveloudness/model_epoch6.pth'
# LOAD_DIR: './training_artifacts/test_9/model_epoch30.pth'

FINETUNE:
  FINETUNE: True 
  FIX_GEN: True
  ENCODER_GUIDE: True
  SPECSUP: True
  APPLY_FLOODING: True

VISUAL:
  VISUAL: False
  KEY: 'freq_formants_hamon'
  INDEX: [0]
  A2A: False
#####################################

TRAIN:
  PROGRESSIVE: False
  W_WEIGHT: 1
  CYCLE_WEIGHT: 1
  BASE_LEARNING_RATE: 0.002
  EPOCHS_PER_LOD: 16
  LEARNING_DECAY_RATE: 0.1
  LEARNING_DECAY_STEPS: [96]
  TRAIN_EPOCHS: 60
  #                    4    8   16    32    64    128    256
  LOD_2_BATCH_8GPU: [512, 256, 128,   64,   32,    32] # If GPU memory ~16GB reduce last number from 32 to 24
  LOD_2_BATCH_4GPU: [64, 64, 64,   64,   32,    16]
  LOD_2_BATCH_2GPU: [64, 64, 64,   64,   32,    16]
  # LOD_2_BATCH_1GPU: [512, 256, 128,   64,   32,    16]
  # LOD_2_BATCH_1GPU: [512, 256, 128,   64,   32,    32]
  # LOD_2_BATCH_1GPU: [512, 256, 128,   64,   32,    16]
  # LOD_2_BATCH_1GPU: [128, 128, 128,   128,   64,    32]
  # LOD_2_BATCH_1GPU: [512, 256, 256,   128,   64,    16]
  LOD_2_BATCH_1GPU: [64, 64, 64,   64,   32,    16]
  BATCH_SIZE : 32
  # BATCH_SIZE : 2
  LEARNING_RATES: [0.0015,  0.0015,   0.0015,    0.002,     0.003,    0.003]
  # LEARNING_RATES: [0.0015,  0.0015,   0.0005,    0.0003,     0.0003,    0.0002]


















# #### perception
# NAME: ecog
# DATASET:
#   PART_COUNT: 16
#   SIZE: 60000
#   FFHQ_SOURCE: /data/datasets/ffhq-dataset/tfrecords/ffhq/ffhq-r%02d.tfrecords
#   PATH: /data/datasets/ffhq-dataset_new/tfrecords/ffhq/splitted/ffhq-r%02d.tfrecords.%03d

#   FLIP_IMAGES: False

#   PART_COUNT_TEST: 4
#   PATH_TEST: /data/datasets/ffhq-dataset_new/tfrecords/ffhq-test/splitted/ffhq-r%02d.tfrecords.%03d

#   SAMPLES_PATH: ''
#   STYLE_MIX_PATH: style_mixing/test_images/set_ecog
#   SPEC_CHANS: 64
#   TEMPORAL_SAMPLES: 128
#   BCTS: True
#   MAX_RESOLUTION_LEVEL: 7
#   # SELECTREGION: ["AUDITORY","BROCA","MOTO","SENSORY","PARIETAL"]
#   # SELECTREGION: ["BROCA","MOTO","SENSORY"]
#   SELECTREGION: ["AUDITORY","BROCA","MOTO","SENSORY"]
#   BLOCKREGION: []
#   SUBJECT: ['NY742']
#   PROD: False
#   PRE_ARTICULATE: False 
#   TRIM: True
# MODEL:
#   #####TAKE OFF CHECKLIST!!!########
#   N_FORMANTS: 6
#   N_FORMANTS_NOISE: 1
#   N_FORMANTS_ECOG: 6
#   WAVE_BASED : True
#   DO_MEL_GUIDE : False 
#   BGNOISE_FROMDATA: True
#   N_FFT : 256 #512
#   NOISE_DB : -50 #-50
#   MAX_DB : 22.5 #probablity 28 is better
#   NOISE_DB_AMP : -25
#   MAX_DB_AMP : 14
#   POWER_SYNTH: True
#   NORMED_MASK: False
#   DUMMY_FORMANT: False
#   LEARNED_MASK: True
#   N_FILTER_SAMPLES: 20
#   CAUSAL: False
#   ANTICAUSAL: False
  


#   LESS_TEMPORAL_FEATURE: True
#   LATENT_SPACE_SIZE: 128
#   LAYER_COUNT: 6
#   MAX_CHANNEL_COUNT: 512
#   START_CHANNEL_COUNT: 16
#   DLATENT_AVG_BETA: 0.995
#   MAPPING_LAYERS: 8
#   TRUNCATIOM_CUTOFF: 5
#   CHANNELS: 1
#   UNIQ_WORDS: 50
#   MAPPING_FROM_ECOG: "ECoGMappingBottleneck"
#   # MAPPING_FROM_ECOG: "Enc3DAttAug"
#   # MAPPING_FROM_ECOG: "Transformer_EncDec"
#   # MAPPING_FROM_ECOG: "ECoGMappingPerformer2Dconv_downsample1_posemb"
#   # MAPPING_FROM_ECOG: "ECoGMappingPerformer3Dconv_downsample1_posemb_flatten"
#   # MAPPING_FROM_ECOG: "ECoGMappingBottleneck3DAttAug"
#   # MAPPING_FROM_ECOG: "ECoGMappingTransformer"
#   ECOG: False #will be overloaded if FINETUNE
#   SUPLOSS_ON_ECOGF: False # will be overloaded to FIX_GEN if FINETUNE,spec supervise loss only apply to ecog encoder
#   W_SUP: False
#   GAN: True
#   GENERATOR: "GeneratorFormant"
#   ENCODER: "EncoderFormant"
#   ECOG_COMPUTE_DB_LOUDNESS: True
#   AVERAGE_W: True
#   TEMPORAL_W: True
#   GLOBAL_W: True
#   TEMPORAL_GLOBAL_CAT: True
#   RESIDUAL: True
#   W_CLASSIFIER: False
#   CYCLE: False
#   ATTENTIONAL_STYLE: True
#   #T            4      8      16    32    64    128 
#   ATTENTION: [False, False, False, False, False, False]
#   HEADS: 1
#   APPLY_PPL: False 
#   APPLY_PPL_D: False
#   PPL_WEIGHT: 100
#   PPL_GLOBAL_WEIGHT: 0
#   PPLD_WEIGHT: 1
#   PPLD_GLOBAL_WEIGHT: 0
#   COMMON_Z: True

#   TRANSFORMER:
#     HIDDEN_DIM : 256
#     DIM_FEEDFORWARD : 256
#     ENCODER_ONLY : True
#     ATTENTIONAL_MASK : False
#     N_HEADS : 8
#     NON_LOCAL: False

#   # ATTENTION: []
# # OUTPUT_DIR: training_artifacts/debug_fitalphaonly_crossentropy
# # OUTPUT_DIR: training_artifacts/debug__
# # OUTPUT_DIR: training_artifacts/debug_han5amppowerloss_reweightflooding_dbmelloss_trim5_casual
# # OUTPUT_DIR: training_artifacts/loudnesscomp_han11_ampamploss
# # OUTPUT_DIR: training_artifacts/loudnesscomp_han15_amppowerloss
# # OUTPUT_DIR: training_artifacts/742_encoder4visA2Abroud2D
# # OUTPUT_DIR: training_artifacts/798_loudnesscomp_han5_amppowerloss_limitmelloss_nodenoiseloss_NewFRange_manualgengauss2_normedmask_amprereweight_silientmore_loudnessfromamp_powernorm_noiseampbias_noiseformantmorefreedom_lessbandwidth
# # OUTPUT_DIR: training_artifacts/749_han5amppowerloss_ecogfinetune
# # OUTPUT_DIR: training_artifacts/ecog_fintune_742_han5amppowerloss_prod_amp
# # OUTPUT_DIR: training_artifacts/717_han5amppowerloss_ecogfinetune_selectall
# # OUTPUT_DIR: training_artifacts/742_han5amppowerloss_dummy_percept
# # OUTPUT_DIR: training_artifacts/742_han5amppowerloss_alphasupbandwfricative
# # OUTPUT_DIR: training_artifacts/749_han5amppowerloss_ecogfintune
# # OUTPUT_DIR: training_artifacts/742_han5amppowerloss_ecogfintune_alphasup3_newlossnoiseamp_causal
# # OUTPUT_DIR: training_artifacts/749_han5amppowerloss_ecogfinetune_woaud
# # OUTPUT_DIR: training_artifacts/717_han5amppowerloss_ecogfinetune_prearti
# # OUTPUT_DIR: training_artifacts/717_han5amppowerloss_ecogfinetune_withparietal
# # OUTPUT_DIR: training_artifacts/742_han5amppowerloss_ecogfinetune_fixedpe_3D_attaugwider_mniemb_realMAXPool_3attauglayers
# # OUTPUT_DIR: training_artifacts/742_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim_causal
# # OUTPUT_DIR: training_artifacts/749_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim_causal_audonly
# # OUTPUT_DIR: training_artifacts/798_loudnesscomp_han5_amppowerloss_limitmelloss_nodenoiseloss_NewFRange_512nfft_gengauss_normedmask_alphapenalty10_hamnonicbias
# # OUTPUT_DIR: training_artifacts/798_loudnesscomp_han5_ecogfinetune_alphasup3_dummyf_learnedmask_monocubic
# # OUTPUT_DIR: training_artifacts/798_loudnesscomp_han5_alphasup3_dummyf_learnedmask_realyrun1run2_monocubic
# # OUTPUT_DIR: training_artifacts/798_loudnesscomp_han5_alphasup3_dummyf_learnedmask_nfiltersample20
# # OUTPUT_DIR: training_artifacts/742_han5amppowerloss_ecogfinetune_alphasup3_groupnorm_ModifiedOutputLayer
# # OUTPUT_DIR: training_artifacts/798_loudnesscomp_han5_ecogfinetune_alphasup3_dummyf_learnedmask_testonWCR_WCR
# # OUTPUT_DIR: training_artifacts/debug_f1f2linearmel
# # OUTPUT_DIR: training_artifacts/ecog_finetune_3ecogformants_han5_specsup_guidance_hamonicformantsemph
# # OUTPUT_DIR: training_artifacts/ecog_finetune_3ecogformants_han5_specsup_guidance_hamonicnoiseformantsemphmore
# # OUTPUT_DIR: training_artifacts/formantsythv2_wavebased_NY742_constraintonFB_Bconstrainrefined_absfreq_4formants_1noiseformants_bgnoise_noisemapping_freqconv_duomask
# # OUTPUT_DIR: training_artifacts/ecog_residual_latent128_temporal_lesstemporalfeature_noprogressive_HBw_ppl_ppld_localreg_ecogf_w_spec_sup
# # OUTPUT_DIR: training_artifacts/ecog_residual_latent128_temporal_lesstemporalfeature_ppl_ppld
# # OUTPUT_DIR: training_artifacts/ecog_residual_cycle_attention3264wStyleIN_specchan64_more_attentfeatures_heads4
# OUTPUT_DIR: training_artifacts/742_han5amppowerloss_alphasup3_percept

# IGNORE_LOADING: True
# # LOAD_DIR: './training_artifacts/ecog_finetune_3ecogformants_han5_specsup_guidance_hamonicformantsemph/model_epoch23.pth'
# # LOAD_DIR: './training_artifacts/debug_f1f2linearmel/model_epoch27.pth'
# # LOAD_DIR: './training_artifacts/debug_fitf1f2freqonly/model_epoch28.pth'
# # LOAD_DIR: './training_artifacts/717_han5amppowerloss_ecogfinetune_prearti/model_epoch26.pth'
# # LOAD_DIR: './training_artifacts/798_loudnesscomp_han5_alphasup3_dummyf_learnedmask_run1run2/model_epoch46.pth'
# # LOAD_DIR: './training_artifacts/798_loudnesscomp_han5_alphasup3_dummyf_learnedmask_nfiltersample20/model_epoch59.pth'
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss_alphasup/model_epoch59.pth'
# # LAOD_DIR: './training_artifacts/742_han5amppowerloss_alphasup/model_epoch31.pth'
# # LOAD_DIR: './training_artifacts/717_han5amppowerloss_alphasup/model_epoch24.pth'
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss/model_epoch33.pth'
# # LOAD_DIR: './training_artifacts/717_han5amppowerloss/model_epoch56.pth'
# # LAOD_DIR: './training_artifacts/742_han5amppowerloss_ecogfinetune_tranformerencdec/model_epoch10.pth'
# # LAOD_DIR: './training_artifacts/loudnesscomp_han5_amppowerloss/model_epoch57.pth'
# # LOAD_DIR: './training_artifacts/ecog_fintune_749_han5amppowerloss_dummy_percept/model_epoch31.pth'
# # LOAD_DIR: './training_artifacts/ecog_fintune_742_han5amppowerloss_prod_amp/model_epoch32.pth'
# # LOAD_DIR: './training_artifacts/742_han5amppowerloss_dummy_percept/model_epoch59.pth'
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_alltask2_percept/model_epoch39.pth'
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss/model_epoch33.pth'
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_selectall/model_epoch36.pth'
# # LOAD_DIR: './training_artifacts/717_han5amppowerloss_ecogfinetune_selectall/model_epoch37.pth'
# # LOAD_DIR: './training_artifacts/debug_han5amppowerloss_dbmelloss_reweightflooding_selectall/model_epoch36.pth'
# # LOAD_DIR: './training_artifacts/debug_han5amppowerloss_dbmelloss_reweightflooding/model_epoch57.pth'
# LOAD_DIR: './training_artifacts/debug_han5amppowerloss_dbmelloss_reweightflooding/model_epoch38.pth' 
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim/model_epoch30.pth'
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim/model_epoch30.pth'
# # LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim/model_epoch30.pth'
# # LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim_causal/model_epoch30.pth'
# # LOAD_DIR: './training_artifacts/717_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim_anticausal_woaud/model_epoch30.pth'
# # LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfinetune_alphasup3_groupnormxdim_anticausal/model_epoch30.pth'
# # LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfintune_alphasup3_newlossnoiseamp_causal/model_epoch49.pth'
# # LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfintune_alphasup3_newlossnoiseamp_anticausal/model_epoch45.pth'
# # LOAD_DIR: './training_artifacts/717_han5amppowerloss_ecogfinetune/model_epoch30.pth' 
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune/model_epoch27.pth'
# # LOAD_DIR: './training_artifacts/717_han5amppowerloss_ecogfinetune_withparietal/model_epoch36.pth'
# # LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfinetune_withparietal/model_epoch35.pth'
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_withparietal/model_epoch33.pth'
# # LOAD_DIR: './training_artifacts/717_han5amppowerloss_ecogfinetune_woaud/model_epoch31.pth'
# # LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfinetune_woaud/model_epoch29.pth'
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_woaud/model_epoch30.pth'
# # LOAD_DIR: './training_artifacts/798_loudnesscomp_han5_amppowerloss_limitmelloss_nodenoiseloss_NewFRange_512nfft_manualgengauss_normedmask_amprereweight_silientmore_dummyformantharmononly_loudnessfromamp2_powernorm_noamplitudesmooth/model_epoch57.pth'
# # LOAD_DIR: './training_artifacts/742_encoder4visA2Abroud2D/model_epoch10.pth'
# # LOAD_DIR: './training_artifacts/717_han5amppowerloss_ecogfinetune_woaud/model_epoch31.pth'
# # LOAD_DIR: './training_artifacts/742_han5amppowerloss_ecogfinetune_woaud/model_epoch29.pth'
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_woaud/model_epoch30.pth'
# # LOAD_DIR: './training_artifacts/749_han5amppowerloss_ecogfinetune_prearti/model_epoch59.pth'
# # LOAD_DIR: './training_artifacts/loudnesscomp_han5_amppowerloss/model_epoch57.pth'
# # LOAD_DIR: './training_artifacts/loudnesscomp_han5_ampamploss/model_epoch59.pth'
# # LOAD_DIR: './training_artifacts/loudnesscomp_han5_ampamploss_denoiswaveloudness/model_epoch6.pth'
# # LOAD_DIR: './training_artifacts/test_9/model_epoch30.pth'

# FINETUNE:
#   FINETUNE: False 
#   FIX_GEN: True
#   ENCODER_GUIDE: True
#   SPECSUP: True
#   APPLY_FLOODING: True

# VISUAL:
#   VISUAL: False
#   KEY: 'freq_formants_hamon'
#   INDEX: [0]
#   A2A: False
# #####################################

# TRAIN:
#   PROGRESSIVE: False
#   W_WEIGHT: 1
#   CYCLE_WEIGHT: 1
#   BASE_LEARNING_RATE: 0.002
#   EPOCHS_PER_LOD: 16
#   LEARNING_DECAY_RATE: 0.1
#   LEARNING_DECAY_STEPS: [96]
#   TRAIN_EPOCHS: 60
#   #                    4    8   16    32    64    128    256
#   LOD_2_BATCH_8GPU: [512, 256, 128,   64,   32,    32] # If GPU memory ~16GB reduce last number from 32 to 24
#   LOD_2_BATCH_4GPU: [64, 64, 64,   64,   32,    16]
#   LOD_2_BATCH_2GPU: [64, 64, 64,   64,   32,    16]
#   # LOD_2_BATCH_1GPU: [512, 256, 128,   64,   32,    16]
#   # LOD_2_BATCH_1GPU: [512, 256, 128,   64,   32,    32]
#   # LOD_2_BATCH_1GPU: [512, 256, 128,   64,   32,    16]
#   # LOD_2_BATCH_1GPU: [128, 128, 128,   128,   64,    32]
#   # LOD_2_BATCH_1GPU: [512, 256, 256,   128,   64,    16]
#   LOD_2_BATCH_1GPU: [64, 64, 64,   64,   32,    16]
#   BATCH_SIZE : 32
#   # BATCH_SIZE : 2
#   LEARNING_RATES: [0.0015,  0.0015,   0.0015,    0.002,     0.003,    0.003]
#   # LEARNING_RATES: [0.0015,  0.0015,   0.0005,    0.0003,     0.0003,    0.0002]